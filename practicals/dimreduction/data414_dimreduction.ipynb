{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herman Kamper, 2020-2021. Licensed under [CC BY-SA 4.0](http://creativecommons.org/licenses/by-sa/4.0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.spatial import distance\n",
    "from sklearn import datasets, decomposition, manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is arguably one of the most famous datasets in machine learning. It consists of $70\\,000$ handwritten digits, each a $28 \\times 28$ grayscale images. It has often been used in the past for benchmarking image classification algorithms, and is still used in studies of new algorithms.\n",
    "\n",
    "Here we will reduce the dimensionality of the images using principle component analysis (PCA). We will also try to visualise the images in a 2-dimensional space.\n",
    "\n",
    "The code below uses scikit-learn to load the MNIST data (this step might take a bit of time). We will only use the first 1000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = datasets.fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "X = X[:1000, :]\n",
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot example\n",
    "plt.imshow(X[0, :].reshape(28, 28), cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in this section is to reduce each $28 \\times 28 = 784$ dimensional image vectors to a vector of $M$ dimensions, where $M < 784$.\n",
    "\n",
    "**Question:** Complete the code below to perform PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Complete the code\n",
    "\n",
    "M = 100  # target number of dimensions\n",
    "\n",
    "# Normalise the data to be zero-mean\n",
    "# Answer: Add your own code here\n",
    "\n",
    "# Calculate the sample covariance matrix\n",
    "# Answer: Add your own code here\n",
    "\n",
    "# Calculate the eigenvalues and -vectors\n",
    "# Answer: Add your own code here\n",
    "# Hint: np.linalg.eig\n",
    "\n",
    "# Find the M eigen vectors corresponding to the largest eigen values\n",
    "# Answer: Add your own code here\n",
    "\n",
    "# Project the data to the lower-dimensional space\n",
    "X_projected = # Answer: Add your own code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the effect of the dimensionality reduction, we can project the reduced data back to the original feature space, and then plot the image. You can do this by (un)commenting the appropriate lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAC2CAYAAAB6fF5CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAP80lEQVR4nO3de7BdZXnH8e9DIvdcjCjINZNAQwnQOBVoGWaQxsilZCBIrekwoCD2YloYbcZCi4JjgGq4SKElgw6UIhRqBwWrBWm4dETCIIS2hjJVQRI8Wm4HkhAuIW//eNepi7PWOdnnZOc9l3w/M2fmnGe9a+137f2u3373WmsnkVJCklTGdiPdAUnalhi6klSQoStJBRm6klSQoStJBRm6klTQuA3diDg/Ir7a7bYdbCtFxP4DLPtuRJzRjceRxrKI+EBErBlk+bqImFGyT6XEWLhPNyI+BnwGmAm8AtwOnJdS6h3JfrWJiAQckFL68Uj3Rd0VEU8DuwNvAeuAfwUWpZTWjWS/2kTEhcD+KaXTttL2bwDWpJT+apjrfwC4KaW0dzf7NRaM+pluRHwG+GtgMTAF+C1gP+B7EbH9AOtMLNdDbWPmp5R2BeYA7wPOG+H+DEtko/74H5dSSqP2B5hMnlF8pF99V+B/gTOrvy8EvgHcRJ4Jf6Kq3VRb53TgZ8ALwAXA08AHa+vfVP0+HUjAGcAzwPPAX9a2czjwA6AX6AGuBravLU/kGUbb/twHfKL6/WPA94Erqm39FDiyqq+u9u+M2rq/CzxW7d9q4MJ+2x5s/7YD/gL4SbX8NmDaSL++Y+2n/pxWf38J+Jfa3zsAS6tx80vgWmCn2vKTgJXVa/gT4LiqvidwB/Ai8GPg7No6F1av143AWuBHwPtryz8LPFstexKYCxwHvAG8WR0/j9fG35Jq3G0A9m/Zp/7HzVHAg9UYXV2Nz09W236j2v6dtf34Z+A54Cngz2rb2Qm4AXgJWEWeRK0Z5Ln+/+OoWu9vge9Wj/d9YA/gymp7/w28r7Zu31hfWz3WgtqyCcBl5OP6KWBR9VgTq+VTgK+Rj+1ngS8CE7o6jkZ6IG9mkB8HbOx7Qvot+3vgltpAeRM4mRwwO/H2ID2oerGOArYnHxhvMnjoXldt5zeA14Ffr5b/Jnm2PbFq+wRwbttgaenzfbw9dDcCH68GwhfJB+s15IP3Q9Wg2bVq/wHgkGr/DiUf1Cd3uH/nAg8Be1fbXtb33PkzpPH4dO053Rv4T+ArteVXksNzGjAJuBO4pFp2OPAyMK96DfcCDqyW3U8OlR3JM+jngLm1sfkacEI1Ti4BHqqWzSIH4Z61sTuz/5juN/6eAWZX4/cdDBK6wL7VGFxYtX0XMKdadgPwxdp62wE/BD5XjcEZ5InEsdXyS4F/r56bfYD/Ymih+zz52NsRWE4OzNP51bFzb23d3yO/AWwH/D6wHnhvteyPyEG8N/BO4B7eHrrfrI6PXYD3AA8Df9jVcTTSA3kzg/w04BcDLLsU+F5toDzQb3l98HyOWsgAO5PfpQcL3b1r7R8GPjpAP84Fbm8bLC1t7+Ptofs/tWWHVOvuXqu90DfIW7Z1JXBFh/v3BNVBXP39XnIoN97M/Bl0PD5NfnNbW71W/wZMrZZFdXDPrLX/beCp6vdlfa9Xv23uQz5HPKlWuwS4oTY276ktOwjYUP2+P/kT0QeBdww0/vuNvy+07NNAoXtefWz3W+8G3h66RwDP9GtzHnB99ftPqWb21d+fZGihe11t2Z8CT9T+PgToHWRbK4GTqt+XUwvR6rlL5Deh3ckTrPqnk4XUAr0bP6P93OfzwG4RMTGltLHfsvdWy/usHmQ7e9aXp5RejYgXNvPYv6j9/ir5lAYR8WvA5cD7yeE2kfwOPxy/rP2+oepb/1rf4x5BfqM5mDyT2AH4p6rd5vZvP+D2iNhUq71FHmTPDrPv26qTU0r3RMTRwM3AbuSP3u8mj4cfRkRf2yDPxCCH63datrcn8GJKaW2t9jPy+OrTfyzuWB0TP46Ic8lBOTsi7gI+nVL6+SD9H+w46W8f8sf0TuwH7BkR9YvbE8izW+g3Rsn7OBT9j4vW4wQgIk4HPk2eQFEt222AftR/3488o++pvYbbMbTnbLNG+4n0H5DfeU6pFyNiF+B48kyjTxpkOz3kjxN96+9E/qg0HH9HPod0QEppMnA++eDa2m4mf3TdJ6U0hXy+sO9xN7d/q4HjU0pTaz87ppQM3GFKKd1PnoEtrUrPkw/+2bXneErKF90gvwYzWzb1c2BaREyq1falwzfDlNLNKaWjyIGRyBedYeDjoX99PfnNos8etd8H6nPbdlaTZ/X1MTYppXRCtbyHHOJ99h1gu1skIvYjnxpcBLwrpTSVfCqj9Vjp16fV5LzZrbYPk1NKs7vZx1Eduimll4GLgL+JiOMi4h0RMZ08w1sD/EOHm/oGMD8ijqzueLiI4QflJPKFkHURcSDwx8PcznAe98WU0msRcTjwB7Vlm9u/a4El1YAkIt4dEScV6vd4diUwLyLmpJQ2kQ/2KyLiPQARsVdEHFu1/Rrw8YiYGxHbVcsOTCmtJl+ouiQidoyIQ4GzgK9v7sEjYlZE/E5E7EA+77uB/AkG8kxwegd3KKwEPlodW+8HTq0t+zrwwYj4SERMjIh3RcSc2vbr99E+DLwSEZ+NiJ0iYkJEHBwRh1XLbwPOi4h3RsTe5FMEW8Mu5DeE5wAi4uPkT4d9bgPOqZ7/qeQLkQCklHqAu4HLImJy9TrNrD7VdM2oDl2AlNKXyLPJpeSwW0F+R5qbUnq9w238iPwi/yP5nW4t+VxYR+v38+fkwFtLPshuHcY2huNPgC9ExFryOdzb+hZ0sH9fIc+S767Wf4h8Dk5bIKX0HPmugguq0mfJdx88FBGvkC/SzKraPky+aHoF+YLa/eTZKeTzhtPJs97bgc+nlL7XQRd2IJ9yep58CuI95GMFfnXq6YWIeHSQbVxAns2+RH6zvrm2f8+QL+B9hnxnxUryhWXIbyIHRURvRHwzpfQWMJ98IfCpqk9fJd8NQLXtn1XL7qbzCdOQpJRWke9O+AH5jeEQ8t0Ofa6rHv8/yHcDfYd8Qbvvzep08um7VeTn5BvkU5ldMya+HNFtEbEr+TzcASmlp0a6P9023vdP6paIOB64NqW032Ybd8mon+l2S0TMj4idq/PBS8m3+zw9sr3qnvG+f1I3VKc+TqhOl+wFfJ786aKYbSZ0yTem/7z6OYB8C9h4muaP9/2TuiHIpzpeIp9eeIJ8uq5cBzwuJamcbWmmK0kjztCVpIIG/UZa9c8USltNSqnEF0saHNva2gYa2850JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JakgQ1eSCjJ0JamgiSPdgbFgwoQJjdqUKVO2aJuLFi1qre+8886N2qxZs1rbfupTn2rUli5d2tp24cKFjdprr73W2vbSSy9t1C666KLWthrbHNvlx7YzXUkqyNCVpIIMXUkqyNCVpIIMXUkqaFzdvbDvvvs2attvv31r2yOPPLJRO+qoo1rbTp06tVH78Ic/PMTeDd+aNWta61dddVWjtmDBgta2a9eubdQef/zx1rb333//EHqnEhzb42dsO9OVpIIMXUkqyNCVpIIMXUkqKFJKAy+MGHjhCJozZ05rffny5Y3aln6lsbRNmzY1ameeeWZr23Xr1nW83Z6enkbtpZdeam375JNPdrzdLZVSimIPVuPYLs+xnTnTlaSCDF1JKsjQlaSCDF1JKsjQlaSCxuTdC9OmTWutr1ixolGbMWPG1u7OoI8P0Nvb26gdc8wxrW3feOONRm2sXaUeCu9eeDvH9vjh3QuSNAoYupJUkKErSQUZupJU0Jj893RffPHF1vrixYsbtRNPPLG17WOPPdaotf0bngNZuXJlozZv3rzWtuvXr2/UZs+e3dr2nHPO6bgPGn8c2+OfM11JKsjQlaSCDF1JKsjQlaSCDF1JKmhMfg14KCZPntxab/sfRJctW9ba9qyzzmrUTjvttEbtlltuGWLv5NeAh8+xPbr5NWBJGgUMXUkqyNCVpIIMXUkqaEx+DXgoXnnllY7bvvzyyx23Pfvssxu1W2+9tbVt2/+CKm0px/bY5ExXkgoydCWpIENXkgoydCWpIENXkgoa918DHopddtmltX7nnXc2akcffXSjdvzxx7euf/fdd29Zx8YxvwZchmO7PL8GLEmjgKErSQUZupJUkKErSQV5Ia0DM2fObNQeffTRRq23t7d1/XvvvbdRe+SRR1rbXnPNNY3aYK/RWOeFtJHl2N56vJAmSaOAoStJBRm6klSQoStJBXkhbZgWLFjQqF1//fWtbSdNmtTxds8///xG7cYbb2xt29PT0/F2RysvpI0+ju3u8EKaJI0Chq4kFWToSlJBhq4kFWToSlJB3r3QRQcffHBr/fLLL2/U5s6d2/F2ly1b1lpfsmRJo/bss892vN3RwLsXxgbH9tB594IkjQKGriQVZOhKUkGGriQV5IW0AqZOndqozZ8/v7Vt29ctI9qvNS1fvrxRmzdv3hB7N7K8kDa2ObYH5oU0SRoFDF1JKsjQlaSCDF1JKsjQlaSCvHthlHn99dcbtYkTJ7a23bhxY6N27LHHtra97777tqhfW4t3L2w7HNuZM11JKsjQlaSCDF1JKsjQlaSC2s9ia1gOPfTQ1vqpp57aqB122GGtbQe6sNBm1apVjdoDDzzQ8fpSpxzb3eNMV5IKMnQlqSBDV5IKMnQlqSBDV5IK8u6FDsyaNatRW7RoUaN2yimntK6/xx57bNHjv/XWW631np6eRm3Tpk1b9Fjatji2y3OmK0kFGbqSVJChK0kFGbqSVNA2eyGt7QLAwoULW9u2XViYPn16t7sEwCOPPNKoLVmypLXtHXfcsVX6oLHNsT26OdOVpIIMXUkqyNCVpIIMXUkqyNCVpILG1d0Lu+++e6N20EEHtba9+uqrG7UDDzyw630CWLFiRaP25S9/ubXtt771rUZtvHz9UcPn2B4/nOlKUkGGriQVZOhKUkGGriQVNOovpE2bNq1RW7ZsWWvbOXPmNGozZszoep8AHnzwwUbtsssua2171113NWobNmzoep80tji2t03OdCWpIENXkgoydCWpIENXkgoydCWpoBG5e+GII45o1BYvXtza9vDDD2/U9tprr673CeDVV19trV911VWN2sUXX9yorV+/vut90tji2NbmONOVpIIMXUkqyNCVpIIMXUkqaEQupC1YsKCj2lCtWrWqUfv2t7/d2nbjxo2N2kBfdezt7d2yjmmb4djW5jjTlaSCDF1JKsjQlaSCDF1JKsjQlaSCIqU08MKIgRdKXZBSipF4XMe2traBxrYzXUkqyNCVpIIMXUkqyNCVpIIMXUkqyNCVpIIMXUkqyNCVpIIMXUkqyNCVpIIMXUkqyNCVpIIMXUkqyNCVpIIMXUkqaNB/T1eS1F3OdCWpIENXkgoydCWpIENXkgoydCWpIENXkgr6P7ZDAiFvOZ5AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reconstruction\n",
    "X_reconstructed = X                                            # comment out this line\n",
    "# X_reconstructed = np.dot(X_projected, W.T) + X.mean(axis=0)  # uncomment\n",
    "\n",
    "# Plot the original and the reconstructed image\n",
    "i_data = 0\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X[i_data, :].reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Reconstructed image\")\n",
    "plt.imshow(X_reconstructed[i_data, :].reshape(28, 28), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"fig/question1.1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Repeat the above with different values of $M$ apart from $M = 100$. What is the effect on the reconstructions?\n",
    "- In the step where we calculate the eigenvalues and -vectors, one option would be to use `np.linalg.eig`. An alternative would be to use the SVD by calling `np.linalg.svd`. If you followed the first option, try to get the same result with the other (or vice-versa).\n",
    "- Use the Jupyter notebook `%timeit` magic command to compare the above two ways of finding the projection vectors. Which one is faster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot all the eigenvalues, calculated in the first cell in Section 3.1, from large to small. What does this plot tell you? Can it help you pick an appropriate $M$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also has a `PCA` class in `sklearn.decomposition`, which you can use from this point onwards. Here is an example of how it can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA in scikit-learn\n",
    "M = 10\n",
    "model = decomposition.PCA(n_components=M)\n",
    "model.fit(X)\n",
    "X_projected = model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualising data with PCA and t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each MNIST image consists of a 784-dimensional vector. It is not possible for us to visuallise data in such high dimensions. This is often the case in many machine learning and data analysis problems. To explore data, it is useful to map it to a 2- or 3-dimensional space which we can visualise. Here we will use PCA and t-SNE to do so. Different visualisation methods rely on different assumptions, and it is useful to therefore apply more than one approach when visualising a particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Using scikit-learn, use PCA to visualise the 1000 digit images in 2-dimensions. Concretely, create a 2-dimensional scatter plot where each item is coloured according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Repeat the above question, but now use t-SNE. You can use the `TSNE` class in `sklearn.manifold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Section 2 is taken partly from the [SciPy Lecture Notes](https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_digits_simple_classif.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand in your completed notebook on SUNLearn\n",
    "\n",
    "You need to hand in your completed Jupyter notebook as a PDF on SUNLearn. To export the notebook to a PDF, you can:\n",
    "\n",
    "- Print the notebook from your browser and then choose `Save as PDF`.\n",
    "- If you are doing the practical on a machine with LaTeX, you can also select `File`$\\rightarrow$ `Download as` $\\rightarrow$ `PDF via LaTeX (.pdf)` directly in the notebook.\n",
    "\n",
    "Upload the PDF on SUNLearn by following the submission steps there. You may submit your work multiple times; only the last submission will be marked. **No late submissions will be accepted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
