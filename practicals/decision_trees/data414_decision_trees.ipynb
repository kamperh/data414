{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herman Kamper, 2020-2021. Licensed under [CC BY-SA 4.0](http://creativecommons.org/licenses/by-sa/4.0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.spatial import distance\n",
    "from sklearn import datasets, tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision tree on the Iris data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we train a decisoin tree on the Iris data set. We will use scikit-learn to train the model, and then visualise the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and visualise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** The code below uses the `dataset` scikit-learn module to load two features from the Iris data set, specifically the petal length and width. The class labels are also loaded. Produce a scatter plot with the petal length on the $x$-axis and petal width on the $y$-axis, with each class given in a different colour. A legend should indicate which colour corresponds to which class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Train a decision tree on the two features from the Iris data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Use the scikit-learn `DecisionTreeClassifier` in `sklearn.tree` to a fit a decision tree to the data.\n",
    "- Read through the parameters of `DecisionTreeClassifier` and see whether you can map each of the parameters to what you learned the way in which decision trees are grown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualise the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Visualise the decision boundaries by completing the code below. Specifically, you need to add the line for making predictions on a grid covering the input feature space. The decision boundary from the model is visualised by then plotting the prediction from the model at each of the grid points.\n",
    "- On the same figure, also plot the data as you did in Section 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Complete the code below\n",
    "\n",
    "# Make grid\n",
    "N = 150\n",
    "grid_x1 = np.linspace(np.min(X[:, 0]) - 0.1, np.max(X[:, 0]) + 0.1, N)\n",
    "grid_x2 = np.linspace(np.min(X[:, 1]) - 0.1, np.max(X[:, 1]) + 0.1, N)\n",
    "grid_x1, grid_x2 = np.meshgrid(grid_x1, grid_x2)\n",
    "X_grid = np.c_[grid_x1.ravel(), grid_x2.ravel()]\n",
    "\n",
    "# Answer: Replace the line below to give the correct output from the model\n",
    "random_predictions = np.random.randint(max(y), size=X_grid.shape[0])\n",
    "grid_predictions = random_predictions.reshape(grid_x1.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(grid_x1, grid_x2, grid_predictions, cmap=ListedColormap([\"C0\", \"C1\", \"C2\"]))\n",
    "plt.xlim([np.min(X[:, 0]) - 0.1, np.max(X[:, 0]) + 0.1])\n",
    "plt.ylim([np.min(X[:, 1]) - 0.1, np.max(X[:, 1]) + 0.1])\n",
    "\n",
    "# Answer: Add the code to also plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "- Use the `plot_tree` function in `sklearn.tree` to visualise the resulting decision tree. You can use `plt.savefig(\"tree.pdf\")` to export the tree to a PDF, where it might be easier to look at the structure.\n",
    "- Repeat the steps in Sections 1.1 and 1.2, but instead of training a decision tree on only two features, now train it on all four of the Iris data set features. How does it differ with the tree trained on only two features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision tree on heart disease data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heart disease dataset (available [here](http://faculty.marshall.usc.edu/gareth-james/ISL/data.html)) contains the records of patients who presented with chest pain and was subsequently diagnosed with having or not having a heart disease.\n",
    "\n",
    "In this section, you will train a decision tree to classify whether an unseen (test) patient has or does not have a heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load the data using the pandas data analysis library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pandas](https://pandas.pydata.org/) is a useful Python library to deal with and visualise tabular data. The code below loads the heart disease data from a CSV file into a pandas `DataFrame`.\n",
    "\n",
    "**Questions:**\n",
    "- Read through the pandas documentation to make sure you understand each of the steps.\n",
    "- Split the data into training and test sets, using 20 of the patients as test patients. (Should you select the last 20 patients as test subjects? Or do you select randomly? Does it matter?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't downloaded the data already with the notebook: Download data\n",
    "import urllib\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/kamperh/data414/main/practicals/decision_trees/heart.csv\",\n",
    "    \"heart.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert discrete features to integers\n",
    "df.ChestPain = pd.factorize(df.ChestPain)[0]\n",
    "df.Thal = pd.factorize(df.Thal)[0]\n",
    "\n",
    "# Construct input design matrix X and output vector y\n",
    "X = df.drop(\"AHD\", axis=1)\n",
    "y = pd.factorize(df.AHD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the DataFrame\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Train and evaluate a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Use scikit-learn to train a decision tree on the training data.\n",
    "- Visualise the tree.\n",
    "- Evaluate the model by calculating the recall, precision and accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer: Add code and new cells here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
